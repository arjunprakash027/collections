{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\.keras\\\\datasets\\\\shakespeare.txt'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "print(text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the text\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ..., 45,  8,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print(text[:13])\n",
    "print(text_as_int[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training examples\n",
    "\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 1.1706926e-03  5.9754925e-04  1.3404323e-03 ...  3.7092376e-03\n",
      "   -4.1774549e-03 -1.3708094e-03]\n",
      "  [ 1.2203853e-03  6.8749231e-04  1.7706987e-03 ...  6.9231335e-03\n",
      "   -7.2856308e-03 -1.9497500e-03]\n",
      "  [-3.3207773e-03 -4.0201158e-03  5.5524078e-03 ...  1.2288874e-02\n",
      "   -7.7592903e-03  1.7145313e-03]\n",
      "  ...\n",
      "  [-6.7947004e-03  7.8829071e-03 -4.8345039e-03 ...  1.8479566e-03\n",
      "   -2.2826833e-03 -6.8860436e-03]\n",
      "  [-5.3630392e-03  6.8287123e-03 -3.2999911e-03 ...  6.1771362e-03\n",
      "   -6.0767895e-03 -5.5540032e-03]\n",
      "  [-4.9173227e-03  5.5857329e-03 -2.4854916e-03 ...  9.8390821e-03\n",
      "   -8.6639421e-03 -4.1386993e-03]]\n",
      "\n",
      " [[-1.1176897e-03  5.8236020e-03 -1.6999191e-03 ...  3.3471285e-04\n",
      "    1.7674230e-03  2.3527243e-03]\n",
      "  [ 1.1965964e-04  1.0118575e-02 -1.8520231e-03 ...  1.1857441e-03\n",
      "    3.2447975e-03  1.9804449e-03]\n",
      "  [ 1.9060748e-03  3.9203735e-03  4.2733550e-04 ...  4.1353598e-04\n",
      "   -1.1757341e-03  7.1871653e-03]\n",
      "  ...\n",
      "  [ 4.5197816e-03  9.3256738e-03 -4.9903961e-03 ...  1.3071320e-02\n",
      "    5.5803754e-04  9.1187772e-04]\n",
      "  [-2.1658167e-03  8.5656894e-03 -1.9227378e-03 ...  1.0671793e-02\n",
      "   -2.3550000e-03  3.4159396e-03]\n",
      "  [-3.8428106e-03  2.3620273e-03  1.7838617e-03 ...  1.5738415e-02\n",
      "   -3.3525941e-03  3.5675387e-03]]\n",
      "\n",
      " [[-2.8072670e-03  2.3019263e-03  1.7405428e-03 ...  3.4421426e-03\n",
      "   -1.2192419e-03  1.8936424e-03]\n",
      "  [ 4.7718408e-03  6.0483431e-03 -4.8445109e-03 ...  4.6763364e-03\n",
      "    5.0796801e-04  3.1695836e-03]\n",
      "  [ 1.8711358e-03  2.9096848e-03 -1.1344769e-03 ...  6.6841580e-03\n",
      "    8.9234952e-04  7.1444968e-03]\n",
      "  ...\n",
      "  [ 8.1449226e-03  7.2152796e-03  1.2491064e-03 ...  1.0296257e-02\n",
      "    1.3985205e-05 -2.3156211e-03]\n",
      "  [ 1.4702318e-03  7.8572212e-03  3.9031494e-03 ...  8.2984483e-03\n",
      "   -4.2218203e-03  2.3711077e-04]\n",
      "  [ 1.2588354e-03  6.8955934e-03  3.2225517e-03 ...  6.9622151e-03\n",
      "   -9.5828064e-03 -2.0950078e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.9160528e-03 -5.0796526e-03  1.3670535e-03 ... -6.0924870e-04\n",
      "   -3.4950315e-03  6.2075434e-03]\n",
      "  [-2.1417465e-03 -2.1909284e-03  1.1146283e-03 ... -5.3038513e-03\n",
      "   -1.2487620e-03 -1.6834195e-03]\n",
      "  [-6.8815700e-03  9.9500187e-04  3.1212210e-03 ... -4.4780336e-03\n",
      "   -4.5936885e-03  3.1663552e-03]\n",
      "  ...\n",
      "  [ 2.5714349e-03  7.5443308e-03 -1.6831059e-03 ...  2.6510053e-03\n",
      "   -4.7888444e-03  3.9780908e-04]\n",
      "  [ 6.2720133e-03  3.5941126e-03 -5.6633693e-03 ...  1.6101170e-04\n",
      "   -1.8865946e-03 -2.8791232e-03]\n",
      "  [ 1.0356875e-02  7.3270742e-03 -1.0147791e-02 ...  1.5459354e-03\n",
      "    7.4366550e-04 -4.8237015e-04]]\n",
      "\n",
      " [[-2.4590450e-03  1.4257436e-03  2.6463747e-03 ...  7.3150620e-03\n",
      "   -2.9443542e-03 -7.1080094e-03]\n",
      "  [ 3.8359365e-03 -4.0842742e-03  5.1300093e-03 ...  9.3686599e-03\n",
      "   -1.6087950e-03 -6.5834876e-03]\n",
      "  [-5.9778872e-04  1.2389454e-03  6.5886904e-03 ...  6.7751566e-03\n",
      "   -4.8176646e-03 -1.8261834e-03]\n",
      "  ...\n",
      "  [-1.5131598e-03  7.4763587e-03  9.2347972e-03 ... -1.2691172e-03\n",
      "   -6.0849003e-03 -3.4906275e-03]\n",
      "  [ 5.4492783e-03  6.2969853e-03  4.5116344e-03 ...  2.5629413e-03\n",
      "   -4.8351530e-03 -6.1238324e-04]\n",
      "  [ 1.0841547e-02  8.7511698e-03 -1.0529184e-03 ...  3.0971316e-03\n",
      "   -1.0971662e-03  6.6152168e-04]]\n",
      "\n",
      " [[-2.6555695e-03 -1.0193340e-03  5.8919359e-03 ...  4.2941738e-03\n",
      "   -2.2919173e-03 -1.0433089e-03]\n",
      "  [ 2.9503336e-04 -4.8522698e-03  5.6263125e-03 ...  2.4205577e-03\n",
      "   -5.2894647e-03  6.1576664e-03]\n",
      "  [-1.2983899e-03 -1.2072359e-03  6.3139866e-03 ...  9.1466559e-03\n",
      "   -7.1726078e-03 -2.4067229e-03]\n",
      "  ...\n",
      "  [-1.9030995e-03  1.9412884e-03 -3.1236000e-04 ...  4.0238071e-04\n",
      "   -4.2636283e-03  1.5527235e-03]\n",
      "  [-3.1038106e-03  3.5969436e-03  1.7257412e-03 ...  8.6080981e-03\n",
      "   -6.1072856e-03 -6.3718087e-03]\n",
      "  [-1.0867825e-03  1.2045742e-03  5.8254949e-04 ...  8.1754820e-03\n",
      "   -8.4026186e-03  1.3330593e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 0.00117069  0.00059755  0.00134043 ...  0.00370924 -0.00417745\n",
      "  -0.00137081]\n",
      " [ 0.00122039  0.00068749  0.0017707  ...  0.00692313 -0.00728563\n",
      "  -0.00194975]\n",
      " [-0.00332078 -0.00402012  0.00555241 ...  0.01228887 -0.00775929\n",
      "   0.00171453]\n",
      " ...\n",
      " [-0.0067947   0.00788291 -0.0048345  ...  0.00184796 -0.00228268\n",
      "  -0.00688604]\n",
      " [-0.00536304  0.00682871 -0.00329999 ...  0.00617714 -0.00607679\n",
      "  -0.005554  ]\n",
      " [-0.00491732  0.00558573 -0.00248549 ...  0.00983908 -0.00866394\n",
      "  -0.0041387 ]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[ 1.1706926e-03  5.9754925e-04  1.3404323e-03 -3.8472763e-03\n",
      " -2.1261976e-03  1.9158999e-04  4.5450067e-04 -1.4889080e-03\n",
      "  2.7511453e-03  4.7153952e-03  6.0821562e-03  3.8726334e-03\n",
      " -2.0176386e-03 -6.8115856e-04  1.0302619e-03 -2.6095053e-04\n",
      "  5.5080338e-04  1.3788808e-03  6.2241000e-03 -1.7562407e-03\n",
      "  2.6553281e-04  3.2422662e-04  6.6543235e-03 -2.8236161e-03\n",
      "  4.0387744e-03 -1.6343321e-03  1.3794593e-03 -9.1939885e-03\n",
      " -9.9842460e-04 -4.8296489e-03 -5.1499583e-04  5.0242627e-03\n",
      " -1.0674355e-02 -9.4260182e-04 -2.2620952e-07  9.1047148e-04\n",
      "  3.8723070e-03  8.7725883e-04  2.2982650e-03 -1.3800992e-03\n",
      " -1.0938349e-03  4.3051150e-03  2.5837666e-03 -3.3336948e-03\n",
      "  5.2596806e-03 -5.2909637e-03  6.2028947e-04 -1.0877289e-03\n",
      " -1.6594389e-03  7.4518169e-03  4.3768166e-03  6.8549695e-04\n",
      "  3.7286682e-03 -4.2764778e-04  5.2372785e-03  2.0592588e-03\n",
      "  2.4246825e-03  3.0692695e-03 -1.6415652e-03 -8.2075493e-03\n",
      "  7.2231237e-04  1.9534610e-03  3.7092376e-03 -4.1774549e-03\n",
      " -1.3708094e-03], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MpblturWGpn&tMHZQNB.nT,-dlNCNKia\\nNvY,kJybG&:UwHeKSWuoyqfXp'Z ,.htl:yq$AQ;VsSrMBaY\\n,vvGDj sOxUVkwl;m-\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels,logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(data, epochs=10, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 500\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "    temprature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions/temprature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romeon botn. You will, my rost\n",
      "It is it bothers: see, you matchat together\n",
      "Not by my guest and hoir to make, and would better strace\n",
      "consul, that we make Romeo's Capitol;\n",
      "Unless the reye know his sport,\n",
      "And hasterful uncleofful veigiance,\n",
      "Not our both to are conceive.\n",
      "Dear not a teal'd of rejour have been,-a king\n",
      "That you shall know it will cure his world. 'Tis true:\n",
      "The kind! how were, a Iset a loving grave?\n",
      "\n",
      "ROMEO:\n",
      "Why stand I was too brgizenge?\n",
      "\n",
      "FORDELEN:\n",
      "She shall, master out of a crown,\n",
      "They do \n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Enter the starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
